{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef8934bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/meinv/anaconda3/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /Users/meinv/anaconda3/lib/python3.11/site-packages (0.17.2)\n",
      "Requirement already satisfied: filelock in /Users/meinv/anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/meinv/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/meinv/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/meinv/anaconda3/lib/python3.11/site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: numpy in /Users/meinv/anaconda3/lib/python3.11/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fc242f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6840, 0.9530, 0.5785],\n",
      "        [0.9320, 0.3355, 0.9697],\n",
      "        [0.8478, 0.6090, 0.8600],\n",
      "        [0.1611, 0.7284, 0.9214],\n",
      "        [0.5668, 0.9989, 0.5032]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "037b5356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while loading conda entry point: anaconda-cloud-auth (cannot import name 'ChannelAuthBase' from 'conda.plugins.types' (/Users/meinv/anaconda3/lib/python3.11/site-packages/conda/plugins/types.py))\n",
      "WARNING:conda.plugins.manager:Error while loading conda entry point: anaconda-cloud-auth (cannot import name 'ChannelAuthBase' from 'conda.plugins.types' (/Users/meinv/anaconda3/lib/python3.11/site-packages/conda/plugins/types.py))\n",
      "Retrieving notices: ...working... DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/notices.json HTTP/1.1\" 404 None\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/notices.json HTTP/1.1\" 404 None\n",
      "done\n",
      "Collecting package metadata (current_repodata.json): / DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "- DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/osx-arm64/current_repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/osx-arm64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "done\n",
      "Solving environment: unsuccessful attempt using repodata from current_repodata.json, retrying with next repodata source.\n",
      "Collecting package metadata (repodata.json): - DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/noarch/repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/osx-arm64/repodata.json HTTP/1.1\" 304 0\n",
      "\\ DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/noarch/repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/osx-arm64/repodata.json HTTP/1.1\" 200 None\n",
      "done\n",
      "Solving environment: failed\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - python=3.7\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/osx-arm64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/osx-arm64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n",
      "Error while loading conda entry point: anaconda-cloud-auth (cannot import name 'ChannelAuthBase' from 'conda.plugins.types' (/Users/meinv/anaconda3/lib/python3.11/site-packages/conda/plugins/types.py))\n",
      "WARNING:conda.plugins.manager:Error while loading conda entry point: anaconda-cloud-auth (cannot import name 'ChannelAuthBase' from 'conda.plugins.types' (/Users/meinv/anaconda3/lib/python3.11/site-packages/conda/plugins/types.py))\n",
      "usage: conda [-h] [--no-plugins] [-V] COMMAND ...\n",
      "conda: error: argument COMMAND: invalid choice: 'activate' (choose from 'clean', 'compare', 'config', 'create', 'info', 'init', 'install', 'list', 'notices', 'package', 'remove', 'uninstall', 'rename', 'run', 'search', 'update', 'upgrade', 'build', 'content-trust', 'convert', 'debug', 'develop', 'doctor', 'index', 'inspect', 'metapackage', 'render', 'skeleton', 'token', 'repo', 'env', 'server', 'pack', 'verify')\n"
     ]
    }
   ],
   "source": [
    "!conda create --name booknlp python=3.7\n",
    "!conda activate booknlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a852d182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: booknlp in /Users/meinv/anaconda3/lib/python3.11/site-packages (1.0.7.1)\n",
      "Requirement already satisfied: torch>=1.7.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from booknlp) (2.2.2)\n",
      "Requirement already satisfied: spacy>=3 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from booknlp) (3.4.4)\n",
      "Requirement already satisfied: transformers<=4.30.0,>=4.11.3 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from booknlp) (4.25.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (2.0.10)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (0.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (1.10.14)\n",
      "Requirement already satisfied: jinja2 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy>=3->booknlp) (3.3.0)\n",
      "Requirement already satisfied: filelock in /Users/meinv/anaconda3/lib/python3.11/site-packages (from torch>=1.7.1->booknlp) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from torch>=1.7.1->booknlp) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/meinv/anaconda3/lib/python3.11/site-packages (from torch>=1.7.1->booknlp) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/meinv/anaconda3/lib/python3.11/site-packages (from torch>=1.7.1->booknlp) (3.1)\n",
      "Requirement already satisfied: fsspec in /Users/meinv/anaconda3/lib/python3.11/site-packages (from torch>=1.7.1->booknlp) (2023.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from transformers<=4.30.0,>=4.11.3->booknlp) (0.15.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from transformers<=4.30.0,>=4.11.3->booknlp) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from transformers<=4.30.0,>=4.11.3->booknlp) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from transformers<=4.30.0,>=4.11.3->booknlp) (0.13.2)\n",
      "Requirement already satisfied: pathlib-abc==0.1.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from pathy>=0.3.5->spacy>=3->booknlp) (0.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->booknlp) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->booknlp) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->booknlp) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3->booknlp) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.0->spacy>=3->booknlp) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.0->spacy>=3->booknlp) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from typer<0.8.0,>=0.3.0->spacy>=3->booknlp) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from jinja2->spacy>=3->booknlp) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.7.1->booknlp) (1.3.0)\n",
      "Collecting en-core-web-sm==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from en-core-web-sm==3.4.1) (3.4.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.10)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.24.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.14)\n",
      "Requirement already satisfied: jinja2 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: pathlib-abc==0.1.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/meinv/anaconda3/lib/python3.11/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install booknlp\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "019c6a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: en\n",
      "Input file: input_file.txt\n",
      "Output folder: output_folder\n",
      "Document ID: 123\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "# 创建ArgumentParser对象\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# 添加命令行参数\n",
    "parser.add_argument('-l', '--language', help='en', required=True)\n",
    "parser.add_argument('-i', '--inputFile', help='booknlp_for_Ao3/RH_10_txt/txt_exports/An_Unlikely_Comfort.txt', required=True)\n",
    "parser.add_argument('-o', '--outputFolder', help='booknlp_for_Ao3/output_Ao3_10/op_An_Unlikely_Comfort', required=True)\n",
    "parser.add_argument('--id', help='001', required=True)\n",
    "\n",
    "# 模拟命令行参数并解析\n",
    "args = parser.parse_args(['-l', 'en', '-i', 'input_file.txt', '-o', 'output_folder', '--id', '123'])\n",
    "\n",
    "# 获取命令行参数的值\n",
    "language = args.language\n",
    "input_file = args.inputFile\n",
    "output_folder = args.outputFolder\n",
    "idd = args.id\n",
    "\n",
    "# 打印命令行参数的值\n",
    "print(\"Language:\", language)\n",
    "print(\"Input file:\", input_file)\n",
    "print(\"Output folder:\", output_folder)\n",
    "print(\"Document ID:\", idd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ddba4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cpu\n",
      "{'pipeline': 'entity,quote,supersense,event,coref', 'model': 'small'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-8_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- startup: 2.710 seconds ---\n",
      "--- spacy: 0.338 seconds ---\n",
      "--- entities: 1.339 seconds ---\n",
      "--- quotes: 0.001 seconds ---\n",
      "--- attribution: 0.141 seconds ---\n",
      "--- name coref: 0.002 seconds ---\n",
      "--- coref: 1.460 seconds ---\n",
      "--- TOTAL (excl. startup): 3.285 seconds ---, 1107 words\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from booknlp.english.english_booknlp import EnglishBookNLP\n",
    "\n",
    "def main():\n",
    "    # 硬编码参数\n",
    "    language = \"en\"\n",
    "    input_file = \"/Users/meinv/Documents/booknlp_for_Ao3/RH_10_txt/txt_exports/An_Unlikely_Comfort.txt\"\n",
    "    output_folder = \"/Users/meinv/Documents/booknlp_for_Ao3/output_Ao3_10/op_An_Unlikely_Comfort\"\n",
    "    idd = \"001\"\n",
    "\n",
    "    # 创建BookNLP对象并处理文本\n",
    "    model_params = {\n",
    "        \"pipeline\": \"entity,quote,supersense,event,coref\",\n",
    "        \"model\": \"small\"\n",
    "    }\n",
    "    booknlp = EnglishBookNLP(model_params)\n",
    "    booknlp.process(input_file, output_folder, idd)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dae93696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "# 创建ArgumentParser对象\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# 添加命令行参数\n",
    "parser.add_argument('-l', '--language', help='en', required=True)\n",
    "parser.add_argument('-i', '--inputFile', help='booknlp_for_Ao3/RH_10_txt/txt_exports/Ever_heard_of_the_rocky.txt', required=True)\n",
    "parser.add_argument('-o', '--outputFolder', help='booknlp_for_Ao3/output_Ao3_10/op_Ever_heard_of_the_rocky', required=True)\n",
    "parser.add_argument('--id', help='001', required=True)\n",
    "\n",
    "# 模拟命令行参数并解析\n",
    "args = parser.parse_args(['-l', 'en', '-i', 'input_file.txt', '-o', 'output_folder', '--id', '123'])\n",
    "\n",
    "# 获取命令行参数的值\n",
    "language = args.language\n",
    "input_file = args.inputFile\n",
    "output_folder = args.outputFolder\n",
    "idd = args.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8c3012f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pipeline': 'entity,quote,supersense,event,coref', 'model': 'small'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-8_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- startup: 2.786 seconds ---\n",
      "--- spacy: 1.434 seconds ---\n",
      "--- entities: 5.268 seconds ---\n",
      "--- quotes: 0.004 seconds ---\n",
      "--- attribution: 5.831 seconds ---\n",
      "--- name coref: 0.054 seconds ---\n",
      "--- coref: 2.490 seconds ---\n",
      "--- TOTAL (excl. startup): 15.113 seconds ---, 7823 words\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from booknlp.english.english_booknlp import EnglishBookNLP\n",
    "\n",
    "def main():\n",
    "    # 硬编码参数\n",
    "    language = \"en\"\n",
    "    input_file = \"/Users/meinv/Documents/booknlp_for_Ao3/RH_10_txt/txt_exports/Ever_heard_of_the_rocky.txt\"\n",
    "    output_folder = \"/Users/meinv/Documents/booknlp_for_Ao3/output_Ao3_10/op_Ever_heard_of_the_rocky\"\n",
    "    idd = \"001\"\n",
    "\n",
    "    # 创建BookNLP对象并处理文本\n",
    "    model_params = {\n",
    "        \"pipeline\": \"entity,quote,supersense,event,coref\",\n",
    "        \"model\": \"small\"\n",
    "    }\n",
    "    booknlp = EnglishBookNLP(model_params)\n",
    "    booknlp.process(input_file, output_folder, idd)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fefda9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pipeline': 'entity,quote,supersense,event,coref', 'model': 'small'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-8_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- startup: 2.455 seconds ---\n",
      "--- spacy: 0.607 seconds ---\n",
      "--- entities: 2.221 seconds ---\n",
      "--- quotes: 0.002 seconds ---\n",
      "--- attribution: 0.878 seconds ---\n",
      "--- name coref: 0.003 seconds ---\n",
      "--- coref: 1.733 seconds ---\n",
      "--- TOTAL (excl. startup): 5.454 seconds ---, 2872 words\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from booknlp.english.english_booknlp import EnglishBookNLP\n",
    "\n",
    "def main():\n",
    "    # 硬编码参数\n",
    "    language = \"en\"\n",
    "    input_file = \"/Users/meinv/Documents/booknlp_for_Ao3/RH_10_txt/txt_exports/Not_for_very_much_longer.txt\"\n",
    "    output_folder = \"/Users/meinv/Documents/booknlp_for_Ao3/output_Ao3_10/op_Not_for_very_much_longer\"\n",
    "    idd = \"001\"\n",
    "\n",
    "    # 创建BookNLP对象并处理文本\n",
    "    model_params = {\n",
    "        \"pipeline\": \"entity,quote,supersense,event,coref\",\n",
    "        \"model\": \"small\"\n",
    "    }\n",
    "    booknlp = EnglishBookNLP(model_params)\n",
    "    booknlp.process(input_file, output_folder, idd)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f72839e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pipeline': 'entity,quote,supersense,event,coref', 'model': 'small'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-8_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- startup: 2.455 seconds ---\n",
      "--- spacy: 2.236 seconds ---\n",
      "--- entities: 7.300 seconds ---\n",
      "--- quotes: 0.006 seconds ---\n",
      "--- attribution: 6.295 seconds ---\n",
      "--- name coref: 0.025 seconds ---\n",
      "--- coref: 2.965 seconds ---\n",
      "--- TOTAL (excl. startup): 18.879 seconds ---, 12176 words\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from booknlp.english.english_booknlp import EnglishBookNLP\n",
    "\n",
    "def main():\n",
    "    # 硬编码参数\n",
    "    language = \"en\"\n",
    "    input_file = \"/Users/meinv/Documents/booknlp_for_Ao3/RH_10_txt/txt_exports/Rocky_Horror_Picture.txt\"\n",
    "    output_folder = \"/Users/meinv/Documents/booknlp_for_Ao3/output_Ao3_10/op_Rocky_Horror_Picture\"\n",
    "    idd = \"001\"\n",
    "\n",
    "    # 创建BookNLP对象并处理文本\n",
    "    model_params = {\n",
    "        \"pipeline\": \"entity,quote,supersense,event,coref\",\n",
    "        \"model\": \"small\"\n",
    "    }\n",
    "    booknlp = EnglishBookNLP(model_params)\n",
    "    booknlp.process(input_file, output_folder, idd)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bebc4683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pipeline': 'entity,quote,supersense,event,coref', 'model': 'small'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-8_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- startup: 2.687 seconds ---\n",
      "--- spacy: 1.181 seconds ---\n",
      "--- entities: 4.191 seconds ---\n",
      "--- quotes: 0.003 seconds ---\n",
      "--- attribution: 2.087 seconds ---\n",
      "--- name coref: 0.008 seconds ---\n",
      "--- coref: 2.288 seconds ---\n",
      "--- TOTAL (excl. startup): 9.783 seconds ---, 6267 words\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from booknlp.english.english_booknlp import EnglishBookNLP\n",
    "\n",
    "def main():\n",
    "    # 硬编码参数\n",
    "    language = \"en\"\n",
    "    input_file = \"/Users/meinv/Documents/booknlp_for_Ao3/RH_10_txt/txt_exports/Science_Fiction_Double.txt\"\n",
    "    output_folder = \"/Users/meinv/Documents/booknlp_for_Ao3/output_Ao3_10/op_Science_Fiction_Double\"\n",
    "    idd = \"005\"\n",
    "\n",
    "    # 创建BookNLP对象并处理文本\n",
    "    model_params = {\n",
    "        \"pipeline\": \"entity,quote,supersense,event,coref\",\n",
    "        \"model\": \"small\"\n",
    "    }\n",
    "    booknlp = EnglishBookNLP(model_params)\n",
    "    booknlp.process(input_file, output_folder, idd)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49ee0152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pipeline': 'entity,quote,supersense,event,coref', 'model': 'small'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-8_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- startup: 2.397 seconds ---\n",
      "--- spacy: 0.342 seconds ---\n",
      "--- entities: 1.527 seconds ---\n",
      "--- quotes: 0.001 seconds ---\n",
      "--- attribution: 0.224 seconds ---\n",
      "--- name coref: 0.002 seconds ---\n",
      "--- coref: 1.519 seconds ---\n",
      "--- TOTAL (excl. startup): 3.621 seconds ---, 1432 words\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from booknlp.english.english_booknlp import EnglishBookNLP\n",
    "\n",
    "def main():\n",
    "    # 硬编码参数\n",
    "    language = \"en\"\n",
    "    input_file = \"/Users/meinv/Documents/booknlp_for_Ao3/RH_10_txt/txt_exports/The_In-Betweens.txt\"\n",
    "    output_folder = \"/Users/meinv/Documents/booknlp_for_Ao3/output_Ao3_10/op_The_In-Betweens\"\n",
    "    idd = \"005\"\n",
    "\n",
    "    # 创建BookNLP对象并处理文本\n",
    "    model_params = {\n",
    "        \"pipeline\": \"entity,quote,supersense,event,coref\",\n",
    "        \"model\": \"small\"\n",
    "    }\n",
    "    booknlp = EnglishBookNLP(model_params)\n",
    "    booknlp.process(input_file, output_folder, idd)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35385d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pipeline': 'entity,quote,supersense,event,coref', 'model': 'small'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-8_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- startup: 2.576 seconds ---\n",
      "--- spacy: 0.539 seconds ---\n",
      "--- entities: 2.178 seconds ---\n",
      "--- quotes: 0.001 seconds ---\n",
      "--- attribution: 0.828 seconds ---\n",
      "--- name coref: 0.002 seconds ---\n",
      "--- coref: 1.679 seconds ---\n",
      "--- TOTAL (excl. startup): 5.236 seconds ---, 2471 words\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from booknlp.english.english_booknlp import EnglishBookNLP\n",
    "\n",
    "def main():\n",
    "    # 硬编码参数\n",
    "    language = \"en\"\n",
    "    input_file = \"/Users/meinv/Documents/booknlp_for_Ao3/RH_10_txt/txt_exports/Thinking_of_Home.txt\"\n",
    "    output_folder = \"/Users/meinv/Documents/booknlp_for_Ao3/output_Ao3_10/op_Thinking_of_Home\"\n",
    "    idd = \"007\"\n",
    "\n",
    "    # 创建BookNLP对象并处理文本\n",
    "    model_params = {\n",
    "        \"pipeline\": \"entity,quote,supersense,event,coref\",\n",
    "        \"model\": \"small\"\n",
    "    }\n",
    "    booknlp = EnglishBookNLP(model_params)\n",
    "    booknlp.process(input_file, output_folder, idd)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d6ade61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pipeline': 'entity,quote,supersense,event,coref', 'model': 'small'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-8_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- startup: 2.393 seconds ---\n",
      "--- spacy: 0.110 seconds ---\n",
      "--- entities: 0.795 seconds ---\n",
      "--- quotes: 0.000 seconds ---\n",
      "--- attribution: 0.071 seconds ---\n",
      "--- name coref: 0.002 seconds ---\n",
      "--- coref: 1.386 seconds ---\n",
      "--- TOTAL (excl. startup): 2.367 seconds ---, 497 words\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from booknlp.english.english_booknlp import EnglishBookNLP\n",
    "\n",
    "def main():\n",
    "    # 硬编码参数\n",
    "    language = \"en\"\n",
    "    input_file = \"/Users/meinv/Documents/booknlp_for_Ao3/RH_10_txt/txt_exports/Unfaithful_Handyman.txt\"\n",
    "    output_folder = \"/Users/meinv/Documents/booknlp_for_Ao3/output_Ao3_10/op_Unfaithful_Handyman\"\n",
    "    idd = \"008\"\n",
    "\n",
    "    # 创建BookNLP对象并处理文本\n",
    "    model_params = {\n",
    "        \"pipeline\": \"entity,quote,supersense,event,coref\",\n",
    "        \"model\": \"small\"\n",
    "    }\n",
    "    booknlp = EnglishBookNLP(model_params)\n",
    "    booknlp.process(input_file, output_folder, idd)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e726c43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pipeline': 'entity,quote,supersense,event,coref', 'model': 'small'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-8_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- startup: 2.904 seconds ---\n",
      "--- spacy: 0.304 seconds ---\n",
      "--- entities: 1.228 seconds ---\n",
      "--- quotes: 0.001 seconds ---\n",
      "--- attribution: 0.971 seconds ---\n",
      "--- name coref: 0.001 seconds ---\n",
      "--- coref: 1.476 seconds ---\n",
      "--- TOTAL (excl. startup): 3.985 seconds ---, 1136 words\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from booknlp.english.english_booknlp import EnglishBookNLP\n",
    "\n",
    "def main():\n",
    "    # 硬编码参数\n",
    "    language = \"en\"\n",
    "    input_file = \"/Users/meinv/Documents/booknlp_for_Ao3/RH_10_txt/txt_exports/Untangle_Memories_And.txt\"\n",
    "    output_folder = \"/Users/meinv/Documents/booknlp_for_Ao3/output_Ao3_10/op_Untangle_Memories_And\"\n",
    "    idd = \"009\"\n",
    "\n",
    "    # 创建BookNLP对象并处理文本\n",
    "    model_params = {\n",
    "        \"pipeline\": \"entity,quote,supersense,event,coref\",\n",
    "        \"model\": \"small\"\n",
    "    }\n",
    "    booknlp = EnglishBookNLP(model_params)\n",
    "    booknlp.process(input_file, output_folder, idd)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25afe3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pipeline': 'entity,quote,supersense,event,coref', 'model': 'small'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-8_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- startup: 3.167 seconds ---\n",
      "--- spacy: 0.590 seconds ---\n",
      "--- entities: 2.552 seconds ---\n",
      "--- quotes: 0.002 seconds ---\n",
      "--- attribution: 1.742 seconds ---\n",
      "--- name coref: 0.007 seconds ---\n",
      "--- coref: 1.785 seconds ---\n",
      "--- TOTAL (excl. startup): 6.690 seconds ---, 3126 words\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from booknlp.english.english_booknlp import EnglishBookNLP\n",
    "\n",
    "def main():\n",
    "    # 硬编码参数\n",
    "    language = \"en\"\n",
    "    input_file = \"/Users/meinv/Documents/booknlp_for_Ao3/RH_10_txt/txt_exports/Were_Not_Lucky_Magenta_x.txt\"\n",
    "    output_folder = \"/Users/meinv/Documents/booknlp_for_Ao3/output_Ao3_10/op_Were_Not_Lucky_Magenta_x\"\n",
    "    idd = \"010\"\n",
    "\n",
    "    # 创建BookNLP对象并处理文本\n",
    "    model_params = {\n",
    "        \"pipeline\": \"entity,quote,supersense,event,coref\",\n",
    "        \"model\": \"small\"\n",
    "    }\n",
    "    booknlp = EnglishBookNLP(model_params)\n",
    "    booknlp.process(input_file, output_folder, idd)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
